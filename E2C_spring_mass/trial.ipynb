{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from tqdm import trange\n",
    "import os\n",
    "import torch\n",
    "import pdb \n",
    "\n",
    "from os import path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimental(output_dir='/Users/avi/Desktop/Food_GVAE-master/E2C_spring_mass/data_2'):\n",
    "    a=torch.load('/Users/avi/Desktop/Food_GVAE-master/E2C_spring_mass/data_exp_osc_02142023.pt')\n",
    "    def normalize(array, min, max):\n",
    "        return (array - min) / (max - min)\n",
    "    a1=[]\n",
    "    a2=[]\n",
    "    a3=[]\n",
    "    a4=[]\n",
    "    a5=[]\n",
    "    a6=[]\n",
    "    a7=[]\n",
    "    a8=[]\n",
    "    for i in range(len(a)):\n",
    "        a1.append(a[i][0][0].detach().numpy())\n",
    "        a2.append(a[i][0][1].detach().numpy())\n",
    "        a3.append(a[i][0][2].detach().numpy())\n",
    "        a4.append(a[i][0][3].detach().numpy())\n",
    "        a5.append(a[i][1][0].detach().numpy())\n",
    "        a6.append(a[i][1][1].detach().numpy())\n",
    "        a7.append(a[i][1][2].detach().numpy())\n",
    "        a8.append(a[i][1][3].detach().numpy())\n",
    "\n",
    "    a1=normalize(np.array(a1),min(a1),max(a1))\n",
    "    a2=normalize(np.array(a2),min(a2),max(a2))\n",
    "    a3=normalize(np.array(a3),min(a3),max(a3))\n",
    "    a4=normalize(np.array(a4),min(a4),max(a4))\n",
    "    a5=normalize(np.array(a5),min(a5),max(a5))\n",
    "    a6=normalize(np.array(a6),min(a6),max(a6))\n",
    "    a7=normalize(np.array(a7),min(a7),max(a7))\n",
    "    a8=normalize(np.array(a8),min(a8),max(a8))\n",
    "\n",
    "    a1=torch.from_numpy(a1)\n",
    "    a2=torch.from_numpy(a2)\n",
    "    a3=torch.from_numpy(a3)\n",
    "    a4=torch.from_numpy(a4)\n",
    "    a5=torch.from_numpy(a5)\n",
    "    a6=torch.from_numpy(a6)\n",
    "    a7=torch.from_numpy(a7)\n",
    "    a8=torch.from_numpy(a8)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        a[i][0][0]=a1[i]\n",
    "        a[i][0][1]=a2[i]\n",
    "        a[i][0][2]=a3[i]\n",
    "        a[i][0][3]=a4[i]\n",
    "        a[i][1][0]=a5[i]\n",
    "        a[i][1][1]=a6[i]\n",
    "        a[i][1][2]=a7[i]\n",
    "        a[i][1][3]=a8[i]\n",
    "    samples=[]\n",
    "    if not path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for i in trange(len(a)):\n",
    "        if(i==0):\n",
    "            a[i][0]=torch.hstack((a[i][0],torch.tensor([0.,0.,0.,0.])))\n",
    "            a[i][1]=torch.hstack((a[i][1],torch.tensor([a[i][1][0],a[i][1][1],a[i][1][2],a[i][1][3]])))\n",
    "        else:\n",
    "            a[i][0]=torch.hstack((a[i][0],torch.tensor([a[i][0][0]-a[i-1][0][0],a[i][0][1]-a[i-1][0][1],a[i][0][2]-a[i-1][0][2],a[i][0][3]-a[i-1][0][3]])))\n",
    "            a[i][1]=torch.hstack((a[i][1],torch.tensor([a[i][1][0]-a[i-1][1][0],a[i][1][1]-a[i-1][1][1],a[i][1][2]-a[i-1][1][2],a[i][1][3]-a[i-1][1][3]])))\n",
    "        initial_state = a[i][0]\n",
    "        after_state =a[i][1]\n",
    "        samples.append({\n",
    "            'before': initial_state.tolist(),\n",
    "            'after': after_state.tolist(),\n",
    "            'control': 0,\n",
    "        })\n",
    "    with open(path.join(output_dir, 'data.json'), 'wt') as outfile:\n",
    "        json.dump(\n",
    "            {\n",
    "                'metadata': {\n",
    "                    'num_samples': 12720,\n",
    "                    'time_created': str(datetime.now()),\n",
    "                    'version': 1\n",
    "                },\n",
    "                'samples': samples\n",
    "            }, outfile, indent=2)\n",
    "\n",
    "\n",
    "# reconstruct the data to be in the same format as a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i in range(len(a1)):\n",
    "    samples.append({\n",
    "            'before': [a1[i],a2[i],a3[i],a4[i]],\n",
    "            'after': [a1[i+1],a2[i+1],a3[i+1],a4[i+1]],\n",
    "            'control': 0,\n",
    "\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the max and min value of a array of numbers normalize the array to be between 0 and 1 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0009971 , 0.00120683, 0.00127894, ..., 0.79143035, 0.7885733 ,\n",
       "       0.7871339 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.6287252e-04, 9.7337860e-04, 8.6538255e-04, ..., 8.8021314e-01,\n",
       "       8.7553924e-01, 8.6848378e-01], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0., -0., -0., -0.]), tensor([ 0.0647,  0.0034,  0.0211, -0.0095])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimental(output_dir='/Users/avi/Desktop/Food_GVAE-master/E2C_spring_mass/data_2'):\n",
    "    a=torch.load('/Users/avi/Desktop/Food_GVAE-master/E2C_spring_mass/data_exp_osc_02142023.pt')\n",
    "    \n",
    "    samples=[]\n",
    "    if not path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for i in trange(len(a)):\n",
    "        if(i==0):\n",
    "            a[i][0]=torch.hstack((a[i][0],torch.tensor([0.,0.,0.,0.])))\n",
    "            a[i][1]=torch.hstack((a[i][1],torch.tensor([a[i][1][0],a[i][1][1],a[i][1][2],a[i][1][3]])))\n",
    "        else:\n",
    "            a[i][0]=torch.hstack((a[i][0],torch.tensor([a[i][0][0]-a[i-1][0][0],a[i][0][1]-a[i-1][0][1],a[i][0][2]-a[i-1][0][2],a[i][0][3]-a[i-1][0][3]])))\n",
    "            a[i][1]=torch.hstack((a[i][1],torch.tensor([a[i][1][0]-a[i-1][1][0],a[i][1][1]-a[i-1][1][1],a[i][1][2]-a[i-1][1][2],a[i][1][3]-a[i-1][1][3]])))\n",
    "        initial_state = a[i][0]\n",
    "        after_state =a[i][1]\n",
    "        samples.append({\n",
    "            'before': initial_state.tolist(),\n",
    "            'after': after_state.tolist(),\n",
    "            'control': 0,\n",
    "        })\n",
    "    with open(path.join(output_dir, 'data.json'), 'wt') as outfile:\n",
    "        json.dump(\n",
    "            {\n",
    "                'metadata': {\n",
    "                    'num_samples': 12720,\n",
    "                    'time_created': str(datetime.now()),\n",
    "                    'version': 1\n",
    "                },\n",
    "                'samples': samples\n",
    "            }, outfile, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
